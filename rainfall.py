# -*- coding: utf-8 -*-
"""Rainfall Prediction Machine Learning Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZrdzE3mOvJaDjaqG6ZynuP-X1FPZdoRX

## **Importing the Dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
import joblib

"""## Data Collection and Preprocessing"""

df = pd.read_csv("C:/Users/Rachit Nigam/OneDrive/Desktop/Rainfall Prediction app/Rainfall.csv")

# Checking Dataset Info
df.info()

# Loading first 5 rows of datasets
df.head()

# loading last 5 rows of the datasets
df.tail()

# Data Shape
df.shape

# unique values in days column
df['day'].unique()

# droping day column from the datset
df = df.drop(columns= ['day'])

# printing columns of the datasets
print(df.columns)

# removing extra spaces from the columns of the datasets
df.columns = df.columns.str.strip()

# now again checking the columns of the datasets
df.columns

# checking the missing values in datasets
df.isnull().sum()

# unique values in winddirection
df["winddirection"].unique()

# handling missing values
df["winddirection"] = df["winddirection"].fillna(df["winddirection"].mode()[0])

df["windspeed"] = df["windspeed"].fillna(df["windspeed"].median())

df["windspeed"]

# checking the missing values in datasets
df.isnull().sum()

# changing categorial value to the numerical
df['rainfall'] = df['rainfall'].map({'yes':1, 'no':0})

df.head()

"""## **Exploratory Data Analysis (EDA)**"""

# setting plot style for all plots
sns.set(style= "whitegrid")

# ploting graph
plt.figure(figsize=(15,10))
for i, column in enumerate(['pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity',
       'cloud', 'sunshine', 'windspeed'], 1):
  plt.subplot(3,3,i)  # Corrected: using 'i' instead of 1
  sns.histplot(df[column], kde=True)
  plt.title(f"Distribution of the {column}")
plt.tight_layout()
plt.show()

# count plot for the rainfall
plt.figure(figsize=(6,4))
sns.countplot(x = 'rainfall', data = df)
plt.title('Distribution of Rainfall')
plt.show()

# heatmap
plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot = True, fmt = '.2f', cmap= 'coolwarm')
plt.title('correlation Heatmap')
plt.show()

# ploting graph
plt.figure(figsize=(15,10))
for i, column in enumerate(['pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity',
       'cloud', 'sunshine', 'windspeed'], 1):
  plt.subplot(3,3,i)  # Corrected: using 'i' instead of 1
  sns.boxplot(df[column])
  plt.title(f"Distribution of the {column}")
plt.tight_layout()
plt.show()

"""# **Data Preprocessing**"""

# Drop Highly Correlated Columns
df = df.drop(columns=['maxtemp', 'temparature', 'mintemp'])

df.head()

df['rainfall'].value_counts()

# Seperate Majority and Minority class
df_majority = df[df['rainfall'] == 1]
df_minority = df[df['rainfall'] == 0]

print(df_majority.shape)
print(df_minority.shape)

# downsample majority class to match the minority class
df_majority_downsampled = resample(df_majority, replace=True, n_samples=len(df_minority), random_state= 42)

print(df_majority_downsampled.shape)
print(df_minority.shape)

finaldf = pd.concat([df_majority_downsampled, df_minority])

finaldf.head()

# shuffle the final dataframe
finaldf = finaldf.sample(frac=1, random_state= 42).reset_index(drop=True)

finaldf.head()

finaldf.value_counts()

finaldf.tail()

#Splitting the data into training data and testing data
X = finaldf.drop(columns= ['rainfall'])
y = finaldf['rainfall']

print(X.shape)
print(y.shape)

print(X)

print(y)

# splitting the dataset into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state= 42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""# **Model Training**"""

rf_model = RandomForestClassifier(random_state= 42)

pram_grid_rf = {
    "n_estimators" : [50,100,200],
    "max_features" : ["sqrt", "log2"],
    "max_depth" : [None, 10, 20, 30],
    "min_samples_split" : [2,5,10],
    "min_samples_leaf" : [1,2,4]
}

# Hypertuning using gridsearch cv
grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=pram_grid_rf, cv=5, n_jobs=-1, verbose=2)
grid_search_rf.fit(X_train,y_train)

best_model_rf = grid_search_rf.best_estimator_
print("the best estimator for the random forest is", best_model_rf)

"""# **Model Evaluation**

"""

cv_scores = cross_val_score(best_model_rf, X_train, y_train, cv=5)
print("Cross-Validation Score:", cv_scores)
print("Mean Cross Validation Score:", np.mean(cv_scores))

# test set performance
y_pred = best_model_rf.predict(X_test)

print("Test set Accuracy", accuracy_score(y_test,y_pred))
print("Test set Confusion Matrix\n", confusion_matrix(y_test,y_pred))
print("Classification report:\n", classification_report(y_test,y_pred))

"""# **Predicition on User Input**"""

# Taking user input for rainfall prediction model

pressure = float(input("Enter atmospheric pressure (hPa): "))
dewpoint = float(input("Enter dew point temperature (Â°C): "))
humidity = float(input("Enter humidity (%): "))
cloud = float(input("Enter cloud cover (%): "))
sunshine = float(input("Enter sunshine duration (hours): "))
winddirection = float(input("Enter wind direction (degrees): "))
windspeed = float(input("Enter wind speed (km/h): "))

# Store inputs in a dictionary (to convert into a DataFrame later if needed)
user_input = {
    "pressure": pressure,
    "dewpoint": dewpoint,
    "humidity": humidity,
    "cloud": cloud,
    "sunshine": sunshine,
    "winddirection": winddirection,
    "windspeed": windspeed
}

# Convert user input dictionary values to a NumPy array
user_input_array = np.array(list(user_input.values())).reshape(1, -1)

# Make prediction
prediction = best_model_rf.predict(user_input_array)

if prediction[0] == 1:
  print("Yes! There are High Chances of Rainfall!")
else:
  print("No! There are no chances of Rainfall!")

# saving model using pkl file
joblib.dump(best_model_rf, "rainfall_model.pkl")
print("Model Saved successfully!")

